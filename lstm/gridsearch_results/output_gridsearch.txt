Sender: LSF System <lsfadmin@eu-c7-113-16>
Subject: Job 233238828: <python -m lstm.submit_gridsearch> in cluster <euler> Done

Job <python -m lstm.submit_gridsearch> was submitted from host <eu-login-17> by user <garcieri> in cluster <euler> at Tue Oct  4 10:29:44 2022
Job was executed on host(s) <eu-c7-113-16>, in queue <normal.4h>, as user <garcieri> in cluster <euler> at Tue Oct  4 10:29:50 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct  4 10:29:50 2022
Terminated at Tue Oct  4 10:30:23 2022
Results reported at Tue Oct  4 10:30:23 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.submit_gridsearch
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1.85 sec.
    Max Memory :                                 23 MB
    Average Memory :                             21.00 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               2025.00 MB
    Max Swap :                                   -
    Max Processes :                              8
    Max Threads :                                9
    Run time :                                   36 sec.
    Turnaround time :                            39 sec.

The output (if any) follows:

Generic job.
Job <233238929> is submitted to queue <normal.120h>.
Generic job.
Job <233238931> is submitted to queue <normal.120h>.
Generic job.
Job <233238934> is submitted to queue <normal.120h>.
Generic job.
Job <233238937> is submitted to queue <normal.120h>.
Sender: LSF System <lsfadmin@eu-a6-004-16>
Subject: Job 233238929: <python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-113-16> by user <garcieri> in cluster <euler> at Tue Oct  4 10:30:21 2022
Job was executed on host(s) <2*eu-a6-004-16>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct  4 10:30:50 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct  4 10:30:50 2022
Terminated at Wed Oct  5 20:02:42 2022
Results reported at Wed Oct  5 20:02:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   201172.02 sec.
    Max Memory :                                 1321 MB
    Average Memory :                             1155.57 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15063.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                47
    Run time :                                   120740 sec.
    Turnaround time :                            120741 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-a6-001-13>
Subject: Job 233238931: <python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-113-16> by user <garcieri> in cluster <euler> at Tue Oct  4 10:30:22 2022
Job was executed on host(s) <2*eu-a6-001-13>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct  4 10:30:50 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct  4 10:30:50 2022
Terminated at Thu Oct  6 13:10:17 2022
Results reported at Thu Oct  6 13:10:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 20000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   313755.22 sec.
    Max Memory :                                 2153 MB
    Average Memory :                             1835.78 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14231.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                47
    Run time :                                   182390 sec.
    Turnaround time :                            182395 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-a6-004-21>
Subject: Job 233238934: <python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-113-16> by user <garcieri> in cluster <euler> at Tue Oct  4 10:30:22 2022
Job was executed on host(s) <2*eu-a6-004-21>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct  4 10:30:50 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct  4 10:30:50 2022
Terminated at Thu Oct  6 14:14:03 2022
Results reported at Thu Oct  6 14:14:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   310501.75 sec.
    Max Memory :                                 1960 MB
    Average Memory :                             1764.26 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14424.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                47
    Run time :                                   186218 sec.
    Turnaround time :                            186221 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-c7-117-03>
Subject: Job 233377397: <python -m lstm.submit_gridsearch> in cluster <euler> Done

Job <python -m lstm.submit_gridsearch> was submitted from host <eu-login-46> by user <garcieri> in cluster <euler> at Thu Oct  6 17:45:59 2022
Job was executed on host(s) <eu-c7-117-03>, in queue <normal.4h>, as user <garcieri> in cluster <euler> at Thu Oct  6 17:46:08 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Thu Oct  6 17:46:08 2022
Terminated at Thu Oct  6 17:46:31 2022
Results reported at Thu Oct  6 17:46:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.submit_gridsearch
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1.75 sec.
    Max Memory :                                 22 MB
    Average Memory :                             20.00 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               2026.00 MB
    Max Swap :                                   -
    Max Processes :                              8
    Max Threads :                                9
    Run time :                                   31 sec.
    Turnaround time :                            32 sec.

The output (if any) follows:

Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233377415> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233377416> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233377417> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233377418> is submitted to queue <normal.120h>.
Sender: LSF System <lsfadmin@eu-g1-001-1>
Subject: Job 233238937: <python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-113-16> by user <garcieri> in cluster <euler> at Tue Oct  4 10:30:23 2022
Job was executed on host(s) <2*eu-g1-001-1>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct  4 10:30:50 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct  4 10:30:50 2022
Terminated at Fri Oct  7 15:11:54 2022
Results reported at Fri Oct  7 15:11:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 30000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   387180.19 sec.
    Max Memory :                                 2211 MB
    Average Memory :                             1808.53 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14173.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   276067 sec.
    Turnaround time :                            276091 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-g1-004-3>
Subject: Job 233377417: <python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-117-03> by user <garcieri> in cluster <euler> at Thu Oct  6 17:46:30 2022
Job was executed on host(s) <2*eu-g1-004-3>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Thu Oct  6 17:46:37 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Thu Oct  6 17:46:37 2022
Terminated at Tue Oct 11 06:15:11 2022
Results reported at Tue Oct 11 06:15:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   544492.00 sec.
    Max Memory :                                 1919 MB
    Average Memory :                             1387.65 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14465.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   390538 sec.
    Turnaround time :                            390521 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-g1-004-3>
Subject: Job 233377418: <python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-117-03> by user <garcieri> in cluster <euler> at Thu Oct  6 17:46:31 2022
Job was executed on host(s) <2*eu-g1-004-3>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Thu Oct  6 17:46:37 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Thu Oct  6 17:46:37 2022
Terminated at Tue Oct 11 06:26:07 2022
Results reported at Tue Oct 11 06:26:07 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   545450.31 sec.
    Max Memory :                                 1828 MB
    Average Memory :                             1383.29 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14556.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   391195 sec.
    Turnaround time :                            391176 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-g1-002-4>
Subject: Job 233377415: <python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-117-03> by user <garcieri> in cluster <euler> at Thu Oct  6 17:46:30 2022
Job was executed on host(s) <2*eu-g1-002-4>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Thu Oct  6 17:46:37 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Thu Oct  6 17:46:37 2022
Terminated at Tue Oct 11 07:09:11 2022
Results reported at Tue Oct 11 07:09:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   549130.62 sec.
    Max Memory :                                 1895 MB
    Average Memory :                             1512.58 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14489.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   393763 sec.
    Turnaround time :                            393761 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-g1-002-4>
Subject: Job 233377416: <python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Done

Job <python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-c7-117-03> by user <garcieri> in cluster <euler> at Thu Oct  6 17:46:30 2022
Job was executed on host(s) <2*eu-g1-002-4>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Thu Oct  6 17:46:37 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Thu Oct  6 17:46:37 2022
Terminated at Tue Oct 11 07:13:25 2022
Results reported at Tue Oct 11 07:13:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   549502.56 sec.
    Max Memory :                                 1852 MB
    Average Memory :                             1495.97 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14532.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   394016 sec.
    Turnaround time :                            394015 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
Sender: LSF System <lsfadmin@eu-g1-006-1>
Subject: Job 233672792: <python -m lstm.submit_gridsearch> in cluster <euler> Done

Job <python -m lstm.submit_gridsearch> was submitted from host <eu-login-29> by user <garcieri> in cluster <euler> at Tue Oct 11 17:09:27 2022
Job was executed on host(s) <eu-g1-006-1>, in queue <normal.4h>, as user <garcieri> in cluster <euler> at Tue Oct 11 17:09:32 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct 11 17:09:32 2022
Terminated at Tue Oct 11 17:09:38 2022
Results reported at Tue Oct 11 17:09:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.submit_gridsearch
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1.28 sec.
    Max Memory :                                 14 MB
    Average Memory :                             14.00 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               2034.00 MB
    Max Swap :                                   -
    Max Processes :                              8
    Max Threads :                                9
    Run time :                                   14 sec.
    Turnaround time :                            11 sec.

The output (if any) follows:

Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233672819> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233672821> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233672823> is submitted to queue <normal.120h>.
Warning: jobs longer than 5 days may be terminated at any time for operational reasons.
Generic job.
Job <233672825> is submitted to queue <normal.120h>.
Sender: LSF System <lsfadmin@eu-g1-015-1>
Subject: Job 233672821: <python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Exited

Job <python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-g1-006-1> by user <garcieri> in cluster <euler> at Tue Oct 11 17:09:37 2022
Job was executed on host(s) <2*eu-g1-015-1>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct 11 17:10:01 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct 11 17:10:01 2022
Terminated at Sat Oct 15 22:42:16 2022
Results reported at Sat Oct 15 22:42:16 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Exited with exit code 135.

Resource usage summary:

    CPU time :                                   505377.88 sec.
    Max Memory :                                 2593 MB
    Average Memory :                             1787.14 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13791.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   365559 sec.
    Turnaround time :                            365559 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/cluster/shadow/.lsbatch/1665500977.233672821: line 8: 128012 Bus error               (core dumped) python -m lstm.run_gridsearch --seed 732 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
Sender: LSF System <lsfadmin@eu-g1-002-4>
Subject: Job 233672823: <python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Exited

Job <python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-g1-006-1> by user <garcieri> in cluster <euler> at Tue Oct 11 17:09:38 2022
Job was executed on host(s) <2*eu-g1-002-4>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct 11 17:10:01 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct 11 17:10:01 2022
Terminated at Sun Oct 16 01:38:51 2022
Results reported at Sun Oct 16 01:38:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Exited with exit code 135.

Resource usage summary:

    CPU time :                                   518285.19 sec.
    Max Memory :                                 2420 MB
    Average Memory :                             1162.60 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13964.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   376155 sec.
    Turnaround time :                            376153 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/cluster/shadow/.lsbatch/1665500978.233672823: line 8: 36311 Bus error               (core dumped) python -m lstm.run_gridsearch --seed 100 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
Sender: LSF System <lsfadmin@eu-g1-012-1>
Subject: Job 233672819: <python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Exited

Job <python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-g1-006-1> by user <garcieri> in cluster <euler> at Tue Oct 11 17:09:37 2022
Job was executed on host(s) <2*eu-g1-012-1>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct 11 17:10:01 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct 11 17:10:01 2022
Terminated at Sun Oct 16 04:40:15 2022
Results reported at Sun Oct 16 04:40:15 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Exited with exit code 135.

Resource usage summary:

    CPU time :                                   392622.25 sec.
    Max Memory :                                 2617 MB
    Average Memory :                             1803.85 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13767.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   387039 sec.
    Turnaround time :                            387038 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/cluster/shadow/.lsbatch/1665500977.233672819: line 8: 22951 Bus error               (core dumped) python -m lstm.run_gridsearch --seed 0 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
Sender: LSF System <lsfadmin@eu-g1-002-4>
Subject: Job 233672825: <python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> in cluster <euler> Exited

Job <python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000> was submitted from host <eu-g1-006-1> by user <garcieri> in cluster <euler> at Tue Oct 11 17:09:38 2022
Job was executed on host(s) <2*eu-g1-002-4>, in queue <normal.120h>, as user <garcieri> in cluster <euler> at Tue Oct 11 17:10:01 2022
</cluster/home/garcieri> was used as the home directory.
</cluster/home/garcieri/rlfr/Robust-optimal-maintenance-planning-through-reinforcement-learning-and-domain-randomization> was used as the working directory.
Started at Tue Oct 11 17:10:01 2022
Terminated at Sun Oct 16 06:04:58 2022
Results reported at Sun Oct 16 06:04:58 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
------------------------------------------------------------

Exited with exit code 135.

Resource usage summary:

    CPU time :                                   399924.91 sec.
    Max Memory :                                 2429 MB
    Average Memory :                             1219.94 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13955.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              3
    Max Threads :                                41
    Run time :                                   392121 sec.
    Turnaround time :                            392120 sec.

The output (if any) follows:

/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead
  warnings.warn('jax.experimental.optimizers is deprecated, '
/cluster/home/garcieri/miniconda3/envs/rlfr/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead
  warnings.warn('jax.experimental.stax is deprecated, '
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/cluster/shadow/.lsbatch/1665500978.233672825: line 8: 36312 Bus error               (core dumped) python -m lstm.run_gridsearch --seed 29 --train_episodes 40000 --test_episodes 500 --update_iterations 10 --gradient_descent_epochs 10 --hidden_sizes "[100, 100, 100]" --learning_rate 0.001 --alpha 0.1 --save_rewards False --save_model False --gridsearch True --polyak 0.995 --replay_size 1000000
